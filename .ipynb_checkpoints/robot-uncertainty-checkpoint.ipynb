{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty-Aware Wrong Label Prediction in Deep Learning Models for Cyber-Physical System Data\n",
    "\n",
    "This repository presents the experiments of the paper:\n",
    "\n",
    "Uncertainty-Aware Wrong Label Prediction in Deep Learning Models for Cyber-Physical System Data\n",
    "\n",
    "**Importing libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Dropout,Dense\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score,\\\n",
    "    precision_score,recall_score,f1_score\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "import itertools\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.svm import SVC\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['f' + str(i) for i in range(24)]\n",
    "col_names.append('label')\n",
    "\n",
    "df = pd.read_csv('robots.zip', skiprows=0, low_memory=False,names=col_names, compression='zip')\n",
    "class_names = df.label.unique()\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.label.values\n",
    "y = LabelBinarizer().fit_transform(y)\n",
    "df.drop([\"label\"], axis=1, inplace=True)\n",
    "\n",
    "X = df.values\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Neural Network and Monte Carlo Dropout methods definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dropout(input_tensor, p=0.5, mc=False):\n",
    "    if mc:\n",
    "        return Dropout(p)(input_tensor, training=True)\n",
    "    else:\n",
    "        return Dropout(p)(input_tensor)\n",
    "\n",
    "def shannon_entropy(vals):\n",
    "    return -1*np.sum([ val*np.log2(val+0.000000000001) for val in vals])\n",
    "\n",
    "def get_model(mc=False, act=\"relu\", dropout_size=0.3, num_of_class=2, input_size=2):\n",
    "    inp = Input(input_size, name='main_input')\n",
    "    x = Dense(100, activation=act,name='Layer-1')(inp)\n",
    "    if mc:\n",
    "        x = get_dropout(x, p=dropout_size, mc=mc)\n",
    "    x = Dense(200, activation=act,name='Layer-2')(x)\n",
    "    if mc:\n",
    "        x = get_dropout(x, p=dropout_size, mc=mc)\n",
    "    x = Dense(100, activation=act,name='Layer-3')(x)\n",
    "    if mc:\n",
    "        x = get_dropout(x, p=dropout_size, mc=mc)\n",
    "    out = Dense(num_of_class, activation='softmax',name='Output-layer')(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=\"rmsprop\",\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Neural Network model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size = 2000\n",
    "batch_size = 10000\n",
    "\n",
    "mcp_save = ModelCheckpoint('robot_model.hdf5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "\n",
    "pred_model_mc = get_model(mc=True, \n",
    "                          num_of_class=4, \n",
    "                          dropout_size=0.02,\n",
    "                          input_size=X.shape[1],\n",
    "                          act=\"relu\")\n",
    "\n",
    "history_mc = pred_model_mc.fit(X_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epoch_size,\n",
    "              callbacks=[mcp_save],\n",
    "              verbose=0,\n",
    "              validation_data=(X_test, y_test))\n",
    "pred_model_mc.load_weights('robot_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training history for accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = ['accuracy','loss']\n",
    "i = 0\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "for plot_type in plots:\n",
    "    ax = fig.add_subplot(1, 2, i+1)\n",
    "    ax.plot(history_mc.history[plot_type])\n",
    "    ax.plot(history_mc.history['val_' + plot_type])\n",
    "    ax.set_title('Model ' + plot_type)\n",
    "    ax.set_ylabel(plot_type)\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.legend(['Train', 'Validation'], loc='upper left')\n",
    "    ax.grid(True)\n",
    "    i =+ 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's find the uncertainty values of the each test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte carlo predictions\n",
    "mc_predictions = []\n",
    "for i in tqdm.tqdm(range(200)):\n",
    "    y_p = pred_model_mc.predict(X_test, batch_size=1000)\n",
    "    mc_predictions.append(y_p)\n",
    "\n",
    "max_means = []\n",
    "preds = []\n",
    "entropy_vals = []\n",
    "std_vals = []\n",
    "for idx in range(X_test.shape[0]):\n",
    "    px = np.array([p[idx] for p in mc_predictions])\n",
    "    #print(px.max(axis=1))\n",
    "    preds.append(px.mean(axis=0).argmax())\n",
    "    max_means.append(px.mean(axis=0).max())\n",
    "    prob_dist = []\n",
    "    for i, (prob, var) in enumerate(zip(px.mean(axis=0), px.std(axis=0))):\n",
    "        prob_dist.append(prob)\n",
    "    entropy_vals.append(shannon_entropy(prob_dist))\n",
    "    #entropy_vals.append(entropy(prob_dist, base=2))\n",
    "    std_vals.append(np.std(px.max(axis=1)))\n",
    "\n",
    "unc_ent_idx = np.flip((np.array(entropy_vals)).argsort()[-3:])\n",
    "unc_std_idx = np.flip((np.array(std_vals)).argsort()[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Questions\n",
    "We aim to explore uncertainty quantification using the Bayesian neural network with the entropy and Softmax prediction probability variance methods. So we form the following Research Questions (RQs) and design the experiments to answer them: \n",
    "- **RQ1** How can the model's decision making be characterized with uncertainty quantification?\n",
    "- **RQ2** Is there any correlation between uncertainty and classification performance?\n",
    "- **RQ3** How can the model's false labelling be predicted by another model using the uncertainty values?\n",
    "- **RQ4** What is the best strategy for the best dropout ratio?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ1: How can the model's decision making be characterized with uncertainty quantification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_iter in range(3):\n",
    "    idx = unc_ent_idx[idx_iter]\n",
    "    p0 = np.array([p[idx] for p in mc_predictions])\n",
    "    prob_txt = []\n",
    "    prob_txt.append(\"True: {}\".format(y_test[idx].argmax()))\n",
    "    prob_txt.append(\", Pred: {}\".format(p0.mean(axis=0).argmax()))\n",
    "\n",
    "    prob_dist = []\n",
    "\n",
    "    for i, (prob, var) in enumerate(zip(p0.mean(axis=0), p0.std(axis=0))):\n",
    "        prob_txt.append(\", Class {} prob: {:2.2f}\\%\".format(i, prob*100))\n",
    "        prob_dist.append(prob)\n",
    "    prob_txt.append(\", Ent: {:.2f}\".format(shannon_entropy(prob_dist)))\n",
    "\n",
    "    prob_txt = \" \".join(prob_txt).strip()\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(12,3))\n",
    "\n",
    "    for i, ax in enumerate(fig.get_axes()):\n",
    "        sns.distplot( p0[:,i],ax=ax, bins=30, fit=norm, kde=False)\n",
    "        ax.set_xlabel(f\"class {i}\")\n",
    "\n",
    "    plt.title(prob_txt)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ2: Is there any correlation between uncertainty and classification performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(data = X_test,\n",
    "                  columns=['f' + str(i) for i in range(X_test.shape[1])])\n",
    "df_results['y'] = y_test.argmax(axis=1)\n",
    "df_results['y_hat'] = preds\n",
    "df_results['unc_entropy'] = entropy_vals\n",
    "df_results['unc_std'] = std_vals\n",
    "\n",
    "discarded_ratio_list = np.linspace(0,0.6,num=50)\n",
    "\n",
    "df_results.sort_values(by=['unc_entropy'],ascending=True,inplace=True)\n",
    "\n",
    "acc_list = []\n",
    "for discarded_ratio in discarded_ratio_list:\n",
    "    tmp_df = df_results.head(np.int(df_results.shape[0] * (1-discarded_ratio)))\n",
    "    y = tmp_df.y.values\n",
    "    y_hat = tmp_df.y_hat.values\n",
    "    acc_list.append(accuracy_score(y,y_hat))\n",
    "plt.plot(discarded_ratio_list,acc_list, '-', marker = '.')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(df_results.y,df_results.y_hat)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ3: How can the model's false labelling be predicted by another model using the uncertainty values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE(sampling_strategy=0.5)\n",
    "\n",
    "X_unc = np.stack((entropy_vals,std_vals),axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "X_unc = scaler.fit_transform(X_unc)\n",
    "\n",
    "mc_ensemble_pred = np.array(mc_predictions).mean(axis=0).argmax(axis=1)\n",
    "wrong_labels = np.abs(y_test.argmax(axis=1) - mc_ensemble_pred)\n",
    "wrong_labels[np.where(wrong_labels > 0)] = 1\n",
    "\n",
    "X_w_train, X_w_test, y_w_train, y_w_test = train_test_split(X_unc, wrong_labels, \n",
    "                                                    test_size=0.7)\n",
    "\n",
    "X_w_train, y_w_train = oversample.fit_resample(X_w_train, y_w_train)\n",
    "\n",
    "clf = SVC(gamma=1000,kernel='poly',C=1000,tol=1e-14, max_iter=1e8)\n",
    "clf.fit(X_w_train, y_w_train)\n",
    "\n",
    "y_pred = clf.predict(X_w_train)\n",
    "cr = classification_report(y_w_train, y_pred)\n",
    "print(cr)\n",
    "\n",
    "ax = plot_decision_regions(X_w_train, y_w_train, clf=clf, legend=1,\n",
    "                      markers='+o',hide_spines=True,colors='red,gray')\n",
    "plt.xlim((-0.1,1.0))\n",
    "plt.ylim((-0.1,1.0))\n",
    "plt.xlabel('Entropy')\n",
    "plt.ylabel('Variance')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_w_train, y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ4: What is the best strategy for the best dropout ratio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_class = 4\n",
    "fig, axes = plt.subplots(1, num_of_class, figsize=(20, 5), sharey=True)\n",
    "for i in range(num_of_class):\n",
    "    kde_plot_title = ' Positive'\n",
    "    if i == 1:\n",
    "        kde_plot_title = ' Negative'\n",
    "\n",
    "    subset = df_results.query('y==' + str(i) + ' and y_hat!=' + str(i))\n",
    "    sns.distplot(subset['unc_entropy'], hist = False, kde = True,\n",
    "                 kde_kws = {'linewidth': 1, 'shade': True},ax=axes[i],\n",
    "                 hist_kws=dict(alpha=1),color=\"salmon\",\n",
    "                 label = r'$y \\ne h_{pred}(\\mathbf{x}) \\Rightarrow$ False' + kde_plot_title)\n",
    "    \n",
    "    subset = df_results.query('y==' + str(i) + ' and y_hat==' + str(i))\n",
    "    sns.distplot( subset['unc_entropy'], hist = False, kde = True,\n",
    "                 kde_kws = {'linewidth': 1, 'shade': True},ax=axes[i],\n",
    "                 hist_kws=dict(alpha=1),color=\"limegreen\",\n",
    "                 label = '$y = h_{pred}(\\mathbf{x}) \\Rightarrow$ True' + kde_plot_title)\n",
    "    axes[i].legend(prop={'size': 14}, \n",
    "                           title = 'Class :' + class_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
